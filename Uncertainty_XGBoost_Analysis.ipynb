{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "__author__ = '@Tssp'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from codvidutils.Autoencoder_Uncertainty_Transformation_main import Transformation_main\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are going to read from: data/train_split_v4.csv and data/test_split_v5.csv\n",
      "Total number of images: 1524\n",
      "shape X: 13600 1524,  disease_ID (Y): 13600 1524\n",
      "Count of classes:  Counter({0: 7966, 2: 5447, 1: 187})\n",
      "New diseaseID shape:  (9097,)\n",
      "New X shape:  (9097, 120000)\n",
      "New Count of classes:  Counter({0: 4500, 2: 4500, 1: 97})\n",
      "Undersample shapes:\n",
      "diseaseID_train.shape: (9097,)\n",
      "X_train.shape: (9097, 120000)\n",
      "X_train.shape: (9097, 200, 200, 3)\n",
      "X_test.shape: (1524, 200, 200, 3)\n",
      "Normal train:  (4500,)\n",
      "Pneumonia train:  (4500,)\n",
      "COVID train:  (97,)\n",
      "*******************************************************\n",
      "Normal test:  (880,)\n",
      "Pneumonia test:  (586,)\n",
      "COVID test:  (58,)\n",
      "(2425, 180, 180, 3)\n",
      "(2425,)\n",
      "X_train.shape:  (11522, 180, 180, 3)\n",
      "diseaseID_train.shape:  (11522,)\n",
      "X_test_news.shape:  (1450, 180, 180, 3)\n",
      "diseaseID_test_news.shape:  (1450,)\n",
      "X_test.shape:  (2974, 180, 180, 3)\n",
      "diseaseID_test.shape:  (2974,)\n",
      "encoder_test.shape (2974, 23, 23, 70)\n",
      "encoder_train.shape (11522, 23, 23, 70)\n",
      "You are going to read from: data/train_split_v4.csv and data/test_split_v5.csv\n",
      "Total number of images: 1524\n",
      "shape X: 13600 1524,  disease_ID (Y): 13600 1524\n",
      "Count of classes:  Counter({0: 7966, 2: 5447, 1: 187})\n",
      "New diseaseID shape:  (9097,)\n",
      "New X shape:  (9097, 120000)\n",
      "New Count of classes:  Counter({0: 4500, 2: 4500, 1: 97})\n",
      "Undersample shapes:\n",
      "diseaseID_train.shape: (9097,)\n",
      "X_train.shape: (9097, 120000)\n",
      "X_train.shape: (9097, 200, 200, 3)\n",
      "X_test.shape: (1524, 200, 200, 3)\n",
      "Normal train:  (4500,)\n",
      "Pneumonia train:  (4500,)\n",
      "COVID train:  (97,)\n",
      "*******************************************************\n",
      "Normal test:  (880,)\n",
      "Pneumonia test:  (586,)\n",
      "COVID test:  (58,)\n",
      "(2425, 180, 180, 3)\n",
      "(2425,)\n",
      "X_train.shape:  (11522, 180, 180, 3)\n",
      "diseaseID_train.shape:  (11522,)\n",
      "X_test_news.shape:  (1450, 180, 180, 3)\n",
      "diseaseID_test_news.shape:  (1450,)\n",
      "X_test.shape:  (2974, 180, 180, 3)\n",
      "diseaseID_test.shape:  (2974,)\n",
      "encoder_test.shape (2974, 23, 23, 70)\n",
      "encoder_train.shape (11522, 23, 23, 70)\n",
      "You are going to read from: data/train_split_v4.csv and data/test_split_v5.csv\n",
      "Total number of images: 1524\n",
      "shape X: 13600 1524,  disease_ID (Y): 13600 1524\n",
      "Count of classes:  Counter({0: 7966, 2: 5447, 1: 187})\n",
      "New diseaseID shape:  (9097,)\n",
      "New X shape:  (9097, 120000)\n",
      "New Count of classes:  Counter({0: 4500, 2: 4500, 1: 97})\n",
      "Undersample shapes:\n",
      "diseaseID_train.shape: (9097,)\n",
      "X_train.shape: (9097, 120000)\n",
      "X_train.shape: (9097, 200, 200, 3)\n",
      "X_test.shape: (1524, 200, 200, 3)\n",
      "Normal train:  (4500,)\n",
      "Pneumonia train:  (4500,)\n",
      "COVID train:  (97,)\n",
      "*******************************************************\n",
      "Normal test:  (880,)\n",
      "Pneumonia test:  (586,)\n",
      "COVID test:  (58,)\n",
      "(2425, 180, 180, 3)\n",
      "(2425,)\n",
      "X_train.shape:  (11522, 180, 180, 3)\n",
      "diseaseID_train.shape:  (11522,)\n",
      "X_test_news.shape:  (1450, 180, 180, 3)\n",
      "diseaseID_test_news.shape:  (1450,)\n",
      "X_test.shape:  (2974, 180, 180, 3)\n",
      "diseaseID_test.shape:  (2974,)\n",
      "encoder_test.shape (2974, 23, 23, 70)\n",
      "encoder_train.shape (11522, 23, 23, 70)\n",
      "You are going to read from: data/train_split_v4.csv and data/test_split_v5.csv\n",
      "Total number of images: 1524\n",
      "shape X: 13600 1524,  disease_ID (Y): 13600 1524\n",
      "Count of classes:  Counter({0: 7966, 2: 5447, 1: 187})\n",
      "New diseaseID shape:  (9097,)\n",
      "New X shape:  (9097, 120000)\n",
      "New Count of classes:  Counter({0: 4500, 2: 4500, 1: 97})\n",
      "Undersample shapes:\n",
      "diseaseID_train.shape: (9097,)\n",
      "X_train.shape: (9097, 120000)\n",
      "X_train.shape: (9097, 200, 200, 3)\n",
      "X_test.shape: (1524, 200, 200, 3)\n",
      "Normal train:  (4500,)\n",
      "Pneumonia train:  (4500,)\n",
      "COVID train:  (97,)\n",
      "*******************************************************\n",
      "Normal test:  (880,)\n",
      "Pneumonia test:  (586,)\n",
      "COVID test:  (58,)\n",
      "(2425, 180, 180, 3)\n",
      "(2425,)\n",
      "X_train.shape:  (11522, 180, 180, 3)\n",
      "diseaseID_train.shape:  (11522,)\n",
      "X_test_news.shape:  (1450, 180, 180, 3)\n",
      "diseaseID_test_news.shape:  (1450,)\n",
      "X_test.shape:  (2974, 180, 180, 3)\n",
      "diseaseID_test.shape:  (2974,)\n",
      "encoder_test.shape (2974, 23, 23, 70)\n",
      "encoder_train.shape (11522, 23, 23, 70)\n",
      "You are going to read from: data/train_split_v4.csv and data/test_split_v5.csv\n",
      "Total number of images: 1524\n",
      "shape X: 13600 1524,  disease_ID (Y): 13600 1524\n",
      "Count of classes:  Counter({0: 7966, 2: 5447, 1: 187})\n",
      "New diseaseID shape:  (9097,)\n",
      "New X shape:  (9097, 120000)\n",
      "New Count of classes:  Counter({0: 4500, 2: 4500, 1: 97})\n",
      "Undersample shapes:\n",
      "diseaseID_train.shape: (9097,)\n",
      "X_train.shape: (9097, 120000)\n",
      "X_train.shape: (9097, 200, 200, 3)\n",
      "X_test.shape: (1524, 200, 200, 3)\n",
      "Normal train:  (4500,)\n",
      "Pneumonia train:  (4500,)\n",
      "COVID train:  (97,)\n",
      "*******************************************************\n",
      "Normal test:  (880,)\n",
      "Pneumonia test:  (586,)\n",
      "COVID test:  (58,)\n",
      "(2425, 180, 180, 3)\n",
      "(2425,)\n",
      "X_train.shape:  (11522, 180, 180, 3)\n",
      "diseaseID_train.shape:  (11522,)\n",
      "X_test_news.shape:  (1450, 180, 180, 3)\n",
      "diseaseID_test_news.shape:  (1450,)\n",
      "X_test.shape:  (2974, 180, 180, 3)\n",
      "diseaseID_test.shape:  (2974,)\n",
      "encoder_test.shape (2974, 23, 23, 70)\n",
      "encoder_train.shape (11522, 23, 23, 70)\n"
     ]
    }
   ],
   "source": [
    "Y_test = []\n",
    "preds = []\n",
    "for it in range(5):\n",
    "    model = 'hdf_files/Uncertainty_AE_Covid_{}.hdf5'.format(it+1)\n",
    "    outputs = Transformation_main('data/train_split_v4.csv', 'data/test_split_v5.csv', model)\n",
    "    Y_test += [outputs['Y_test']]\n",
    "    preds += [np.loadtxt('log/preds_XGBr_Uncertainty_{}.txt'.format(it+1), delimiter=',')]\n",
    "    del outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [0.24281604 0.5311683  0.44169112 ... 0.55988932 0.60686467 0.31685401]\n",
      "Std: [0.00082755 0.0072302  0.0052276  ... 0.00376151 0.00064119 0.00093641]\n"
     ]
    }
   ],
   "source": [
    "predictive_mean = np.mean(preds, axis=0)\n",
    "predictive_variance = np.var(preds, axis=0)\n",
    "print(\"Mean: {}\\nStd: {}\".format(predictive_mean, predictive_variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following Gal's approach:\n",
    "## $$\\tau = \\frac{1-p}{2Nl_2}$$\n",
    "## where $p$ is the probability of the dropout layers, $N$ the number of predictions and $l_2$ the regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau: 18.0\n",
      "Error: 0.05555555555555555\n",
      "Total Error: [0.23745127 0.25057087 0.24654241 ... 0.24355095 0.23705854 0.23768039]\n"
     ]
    }
   ],
   "source": [
    "p = 0.10\n",
    "N = len(preds)\n",
    "l2 = 0.005\n",
    "tau = (1 - p)/(2*N*l2)\n",
    "E_s = 1/tau\n",
    "E_t = np.sqrt(predictive_variance + E_s)\n",
    "print(\"tau: {}\\nError: {}\\nTotal Error: {}\".format(tau, E_s, E_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
